{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77471ca7-d8a2-4e4c-9723-ddf6e7b9c639",
   "metadata": {
    "papermill": {
     "duration": 0.007698,
     "end_time": "2025-04-14T23:20:50.172624",
     "exception": false,
     "start_time": "2025-04-14T23:20:50.164926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Transformação da Camada Silver — Open Meteo\n",
    "Neste notebook transformamos os dados brutos da camada Bronze em dados limpos e prontos para análise, compondo a camada Silver do Data Lake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce424a1f-1587-45b6-ac69-817ce61538cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:20:50.183280Z",
     "iopub.status.busy": "2025-04-14T23:20:50.182591Z",
     "iopub.status.idle": "2025-04-14T23:20:50.591598Z",
     "shell.execute_reply": "2025-04-14T23:20:50.590558Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.416345,
     "end_time": "2025-04-14T23:20:50.593254",
     "exception": false,
     "start_time": "2025-04-14T23:20:50.176909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d2feca-60cd-4c82-8e86-06294d10ae68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:20:50.598764Z",
     "iopub.status.busy": "2025-04-14T23:20:50.598406Z",
     "iopub.status.idle": "2025-04-14T23:20:54.867918Z",
     "shell.execute_reply": "2025-04-14T23:20:54.866767Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 4.275791,
     "end_time": "2025-04-14T23:20:54.870634",
     "exception": false,
     "start_time": "2025-04-14T23:20:50.594843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/14 20:20:52 WARN Utils: Your hostname, obi-wan-kenote resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/14 20:20:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/kenote_ubuntu/projetos/Airflow/.venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/kenote_ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/kenote_ubuntu/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7e266975-6a4f-4dfb-9e23-dc14a06ab2db;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;2.3.0 in central\n",
      "\tfound io.delta#delta-storage;2.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 132ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;2.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7e266975-6a4f-4dfb-9e23-dc14a06ab2db\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/6ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/14 20:20:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder \\\n",
    "    .appName(\"SilverTransformOpenMeteo\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c41904-cd6a-4600-9fc4-113e40dfa962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:20:54.878204Z",
     "iopub.status.busy": "2025-04-14T23:20:54.877850Z",
     "iopub.status.idle": "2025-04-14T23:21:07.161972Z",
     "shell.execute_reply": "2025-04-14T23:21:07.159295Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 12.291862,
     "end_time": "2025-04-14T23:21:07.164280",
     "exception": false,
     "start_time": "2025-04-14T23:20:54.872418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 3) / 3]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/14 20:21:02 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:=============>                                          (12 + 12) / 50]\r",
      "\r",
      "[Stage 3:========================>                               (22 + 12) / 50]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:======================================>                 (34 + 12) / 50]\r",
      "\r",
      "[Stage 3:=====================================================>   (47 + 3) / 50]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+--------+\n",
      "|     city|      date|temp_min|temp_max|\n",
      "+---------+----------+--------+--------+\n",
      "|São Paulo|2025-04-18|    17.3|    26.8|\n",
      "|São Paulo|2025-04-19|    17.8|    25.5|\n",
      "|São Paulo|2025-04-20|    16.0|    21.6|\n",
      "|São Paulo|2025-04-21|    15.3|    20.8|\n",
      "|São Paulo|2025-04-22|    14.9|    20.8|\n",
      "+---------+----------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caminho absoluto da camada Bronze\n",
    "bronze_path = \"/home/kenote_ubuntu/projetos/Airflow/data/bronze/open_meteo\"\n",
    "\n",
    "# Leitura dos dados brutos (Delta)\n",
    "df_bronze = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "# Visualizando as primeiras linhas\n",
    "df_bronze.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55eb2224-edff-4969-8f8a-24cd94d8b991",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:21:07.171260Z",
     "iopub.status.busy": "2025-04-14T23:21:07.170983Z",
     "iopub.status.idle": "2025-04-14T23:21:07.229633Z",
     "shell.execute_reply": "2025-04-14T23:21:07.227886Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.064795,
     "end_time": "2025-04-14T23:21:07.231982",
     "exception": false,
     "start_time": "2025-04-14T23:21:07.167187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renomeando colunas para padrão snake_case (caso necessário)\n",
    "df_silver = df_bronze.select(\n",
    "    col(\"city\").alias(\"city\"),\n",
    "    col(\"date\").alias(\"date\"),\n",
    "    col(\"temp_min\").alias(\"temperature_min_c\"),\n",
    "    col(\"temp_max\").alias(\"temperature_max_c\")\n",
    ")\n",
    "\n",
    "# Conversão de tipos, se necessário\n",
    "# (Spark já infere corretamente, mas vamos garantir que temperatura seja float)\n",
    "df_silver = df_silver.withColumn(\"temperature_min_c\", col(\"temperature_min_c\").cast(\"double\"))\n",
    "df_silver = df_silver.withColumn(\"temperature_max_c\", col(\"temperature_max_c\").cast(\"double\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5cb6c9-b09d-4c0c-ae98-40170de74d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:21:07.239032Z",
     "iopub.status.busy": "2025-04-14T23:21:07.238569Z",
     "iopub.status.idle": "2025-04-14T23:21:07.631344Z",
     "shell.execute_reply": "2025-04-14T23:21:07.629075Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.398966,
     "end_time": "2025-04-14T23:21:07.633865",
     "exception": false,
     "start_time": "2025-04-14T23:21:07.234899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----------------+-----------------+\n",
      "|       city|      date|temperature_min_c|temperature_max_c|\n",
      "+-----------+----------+-----------------+-----------------+\n",
      "|   Cabedelo|2025-04-23|             25.8|             28.3|\n",
      "|   Cabedelo|2025-04-24|             25.3|             28.2|\n",
      "|   Cabedelo|2025-04-25|             25.0|             28.2|\n",
      "|   Cabedelo|2025-04-26|             25.4|             28.4|\n",
      "|   Cabedelo|2025-04-27|             25.8|             28.3|\n",
      "|   Cabedelo|2025-04-28|             25.7|             28.3|\n",
      "|   Cabedelo|2025-04-29|             26.4|             28.9|\n",
      "|João Pessoa|2025-04-14|             24.3|             30.8|\n",
      "|João Pessoa|2025-04-15|             25.7|             31.3|\n",
      "|  São Paulo|2025-04-18|             17.3|             26.8|\n",
      "+-----------+----------+-----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- temperature_min_c: double (nullable = true)\n",
      " |-- temperature_max_c: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualização dos dados tratados\n",
    "df_silver.show(10)\n",
    "df_silver.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b2bbd2e-cfed-4c53-a1c7-cf3e45f28f1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:21:07.642322Z",
     "iopub.status.busy": "2025-04-14T23:21:07.641298Z",
     "iopub.status.idle": "2025-04-14T23:21:13.956683Z",
     "shell.execute_reply": "2025-04-14T23:21:13.954960Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 6.320866,
     "end_time": "2025-04-14T23:21:13.958417",
     "exception": false,
     "start_time": "2025-04-14T23:21:07.637551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/04/14 20:21:08 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 20:======================================================> (49 + 1) / 50]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Salvando a camada silves como Delta\n",
    "\n",
    "# Caminho absoluto da camada Silver\n",
    "silver_path = \"/home/kenote_ubuntu/projetos/Airflow/data/silver/open_meteo\"\n",
    "\n",
    "# Salvando os dados limpos no formato Delta\n",
    "df_silver.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(silver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca2b70e-a78c-4f2b-8826-572d88abf767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T23:21:13.967012Z",
     "iopub.status.busy": "2025-04-14T23:21:13.966472Z",
     "iopub.status.idle": "2025-04-14T23:21:14.443741Z",
     "shell.execute_reply": "2025-04-14T23:21:14.442369Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.483452,
     "end_time": "2025-04-14T23:21:14.446324",
     "exception": false,
     "start_time": "2025-04-14T23:21:13.962872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------------+-----------------+\n",
      "|  city|      date|temperature_min_c|temperature_max_c|\n",
      "+------+----------+-----------------+-----------------+\n",
      "|Bogotá|2025-04-17|             11.6|             20.6|\n",
      "|Bogotá|2025-04-18|             13.4|             21.3|\n",
      "|Bogotá|2025-04-19|             13.1|             21.6|\n",
      "|Bogotá|2025-04-20|             13.3|             19.3|\n",
      "|Bogotá|2025-04-21|             11.5|             19.0|\n",
      "+------+----------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- temperature_min_c: double (nullable = true)\n",
      " |-- temperature_max_c: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Verificando os dados salvos\n",
    "\n",
    "# Lendo novamente para validar o conteúdo da Silver\n",
    "df_check = spark.read.format(\"delta\").load(silver_path)\n",
    "\n",
    "# Exibindo os dados para garantir que tudo está correto\n",
    "df_check.show(5)\n",
    "df_check.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ddb42-bb45-49e7-98ce-a0c3a0379dac",
   "metadata": {
    "papermill": {
     "duration": 0.003589,
     "end_time": "2025-04-14T23:21:14.455006",
     "exception": false,
     "start_time": "2025-04-14T23:21:14.451417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusao\n",
    "\n",
    "✅ Leitura dos dados da Bronze (caminho absoluto)\n",
    "✅ Transformações de limpeza e padronização\n",
    "✅ Salvar resultado da Silver como Delta\n",
    "✅ Comentários bem didáticos\n",
    "✅ Verificação final do conteúdo salvo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.954209,
   "end_time": "2025-04-14T23:21:17.081100",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/kenote_ubuntu/projetos/Airflow/notebooks/silver/03_transform_silver_open_meteo.ipynb",
   "output_path": "/home/kenote_ubuntu/projetos/Airflow/notebooks/executed/03_transform_silver_open_meteo_20250414.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T23:20:49.126891",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}