Claro! Abaixo estÃ¡ um `README.md` completo e organizado para documentar todo o seu projeto Open-Meteo, incluindo os notebooks, execuÃ§Ã£o com JupyterLab e Airflow, e os detalhes da DAG, ambiente e dependÃªncias.

---

```markdown
# ðŸŒ¦ï¸ Open-Meteo Pipeline â€” Projeto de Engenharia de Dados

Este projeto implementa um pipeline de previsÃ£o climÃ¡tica baseado em notebooks orquestrados com **Apache Airflow** e processados com **Papermill**. Os dados sÃ£o tratados com **PySpark** e **Delta Lake**, e visualizados com **Plotly**.

---

## ðŸ“ Estrutura do Projeto

```bash
projetos/Airflow/
â”œâ”€â”€ .venv/                        # Ambiente virtual Python
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ open_meteo_pipeline_dag.py   # DAG principal do Airflow
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ extraction/              # Notebook de extraÃ§Ã£o de dados
â”‚   â”‚   â””â”€â”€ 01_extract_open_meteo.ipynb
â”‚   â”œâ”€â”€ bronze/                  # ValidaÃ§Ã£o inicial (camada bronze)
â”‚   â”‚   â””â”€â”€ 02_validate_bronze_open_meteo.ipynb
â”‚   â”œâ”€â”€ silver/                  # TransformaÃ§Ã£o (camada silver)
â”‚   â”‚   â””â”€â”€ 03_transform_silver_open_meteo.ipynb
â”‚   â”œâ”€â”€ gold/                    # Enriquecimento (camada gold)
â”‚   â”‚   â””â”€â”€ 04_prepare_gold_open_meteo.ipynb
â”‚   â”œâ”€â”€ dashboard/               # GeraÃ§Ã£o de dashboard
â”‚   â”‚   â””â”€â”€ 05_dashboard_open_meteo.ipynb
â”‚   â””â”€â”€ executed/                # Resultados dos notebooks executados pelo Airflow
â”œâ”€â”€ data/                        # Dados Delta Lake
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ gold/
â””â”€â”€ requirements.txt             # DependÃªncias do projeto
```

---

## ðŸ§ª Como rodar

### 1. Clone o repositÃ³rio e entre na pasta

```bash
cd ~/projetos/Airflow
```

### 2. Crie o ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

> ðŸ“Œ **Nota:** Certifique-se de instalar tambÃ©m `pyspark`, `delta-spark`, `ipywidgets`, `plotly`, entre outros que aparecem abaixo.

---

## ðŸš€ JupyterLab

### Inicie o servidor Jupyter:

```bash
jupyter lab
```

### Acesse via navegador:
```
http://localhost:8888
```

> **Dica:** Habilite a visualizaÃ§Ã£o de arquivos ocultos no menu **View â†’ Show Hidden Files** para visualizar a pasta `.venv`.

---

## ðŸŽ¯ Apache Airflow

### InicializaÃ§Ã£o do banco de dados

```bash
airflow db migrate
```

### Crie um usuÃ¡rio administrador:

```bash
airflow users create \
  --username admin \
  --firstname Admin \
  --lastname User \
  --role Admin \
  --email admin@example.com \
  --password admin
```

### Inicie o scheduler e webserver:

```bash
airflow scheduler
airflow webserver
```

Acesse o Airflow via navegador:

```
http://localhost:8080
```

---

## âš™ï¸ DAG principal

A DAG estÃ¡ localizada em:

```bash
dags/open_meteo_pipeline_dag.py
```

Ela orquestra os seguintes notebooks:

1. `extraction/01_extract_open_meteo.ipynb`
2. `bronze/02_validate_bronze_open_meteo.ipynb`
3. `silver/03_transform_silver_open_meteo.ipynb`
4. `gold/04_prepare_gold_open_meteo.ipynb`
5. `dashboard/05_dashboard_open_meteo.ipynb`

Execute a DAG manualmente pela interface ou via terminal:

```bash
airflow dags trigger open_meteo_pipeline_dag
```

---

## ðŸ“¦ Requisitos (requirements.txt)

```txt
apache-airflow==2.10.4
apache-airflow[celery, http, sqlite]
apache-airflow-providers-papermill
apache-airflow-providers-docker
apache-airflow-providers-cncf-kubernetes
apache-airflow-providers-common-io
papermill
pyspark
delta-spark
pandas
plotly
ipywidgets
matplotlib
seaborn
requests
```

> âœ… **Dica:** Para instalar Delta Lake:
```bash
pip install delta-spark
```

---

## ðŸ§¼ Problemas comuns

| Erro | SoluÃ§Ã£o |
|------|---------|
| `ModuleNotFoundError: No module named 'pyspark'` | Execute `pip install pyspark` |
| `FileNotFoundError` nos notebooks | Verifique o caminho correto no PapermillOperator |
| Widgets nÃ£o interativos no dashboard | Isso Ã© esperado ao executar via Airflow. Use `fig.show()` por cidade. |

---

## ðŸ§  Sobre o projeto

Este pipeline demonstra prÃ¡ticas modernas de **engenharia de dados com notebooks orquestrados**, usando o melhor dos mundos: Jupyter para prototipagem + Airflow para produÃ§Ã£o.

---

**Desenvolvido por:** _[Seu Nome Aqui]_ ðŸ§ª  
```

---

Se quiser que eu gere esse conteÃºdo automaticamente dentro de um `README.md` no seu ambiente ou salve no projeto, me avise que te passo o comando ou atÃ© o script.
